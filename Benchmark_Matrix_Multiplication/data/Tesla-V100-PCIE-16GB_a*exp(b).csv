n_processors,cpu_memory,gpu_name,gpu_memory,data_type,size1,size2,operation,numpy,numexpr,numba_cpu,numba_gpu,pytorch
24,440.90975189208984,Tesla V100-PCIE-16GB,15.78173828125,<class 'numpy.float32'>,100,100,a*exp(b),2.982013507142775e-06,0.0004321573989999966,3.0786444985713905e-06,0.0014421546107142344,7.769559442858086e-05
24,440.90975189208984,Tesla V100-PCIE-16GB,15.78173828125,<class 'numpy.float32'>,1000,1000,a*exp(b),0.00039744053457135516,0.0005893131675714878,0.00042798026814281395,0.004855860305714747,0.000938265726285798
24,440.90975189208984,Tesla V100-PCIE-16GB,15.78173828125,<class 'numpy.float32'>,10000,10000,a*exp(b),0.17511989802856728,0.031773674457151305,0.17426568362857323,0.26353477399996855,0.09535574244285791
24,440.90975189208984,Tesla V100-PCIE-16GB,15.78173828125,<class 'numpy.float32'>,100000,10000,a*exp(b),1.738480907428636,0.28479482242866133,1.7474476704285604,2.6887384551427465,0.9571765117142864
24,440.90975189208984,Tesla V100-PCIE-16GB,15.78173828125,<class 'numpy.float32'>,100000,100000,a*exp(b),17.508171226571513,2.8324364292856052,17.42119853099991,OOM,OOM
