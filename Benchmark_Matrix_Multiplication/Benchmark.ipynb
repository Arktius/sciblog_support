{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark of Matrix Multiplications\n",
    "On this benchmark we compare several operations using numpy, numexpr and numba (CPU&GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) \n",
      "[GCC 7.3.0]\n",
      "Numpy version: 1.16.0\n",
      "Pandas version: 0.23.4\n",
      "Numexpr version: 2.6.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from numba import vectorize\n",
    "import math\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import bokeh\n",
    "from utils import (get_number_processors, get_ram_memory, get_total_gpu_memory, \n",
    "                   get_gpu_name, get_cuda_version, get_cudnn_version, AttributeDict)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Numexpr version: {}\".format(ne.__version__))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a,b):\n",
    "    return a*b\n",
    "\n",
    "def exponential(a, b):\n",
    "    return a*np.exp(b)\n",
    "\n",
    "def sine(a, b):\n",
    "    return a*np.sin(b)\n",
    "\n",
    "# A general function that multiplies an arbitrary number of matrices\n",
    "# is 28% slower than directly multiplying the factors.\n",
    "# The function multiply_list is not used, just leaving it here for reference\n",
    "def multiply_list(l):\n",
    "    return reduce(lambda x, y: x*y, l) \n",
    "\n",
    "def multiply3(a, b, c):\n",
    "    return a*b*c\n",
    "\n",
    "def multiply5(a, b, c, d, e):\n",
    "    return a*b*c*d*e\n",
    "\n",
    "def exponential_sine(a, b, c):\n",
    "    return a*np.exp(b)*np.sin(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function with numpexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_multiply(a,b):\n",
    "    return ne.evaluate(\"a*b\")\n",
    "\n",
    "def ne_exponential(a, b):\n",
    "    return ne.evaluate(\"a*exp(b)\")\n",
    "\n",
    "def ne_sine(a, b):\n",
    "    return ne.evaluate(\"a*sin(b)\")\n",
    "\n",
    "def ne_multiply3(a, b, c):\n",
    "    return ne.evaluate(\"a*b*c\")\n",
    "\n",
    "def ne_multiply5(a, b, c, d, e):\n",
    "    return ne.evaluate(\"a*b*c*d*e\")\n",
    "\n",
    "def ne_exponential_sine(a, b, c):\n",
    "    return ne.evaluate(\"a*exp(b)*sin(c)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for numba\n",
    "NOTE: For numba solutions, having a solution empty vector speeds up around 10%\n",
    "```\n",
    "r0 = np.empty((S1, S2), dtype=np.int16)\n",
    "r0 = multicpu(a, b)\n",
    "```\n",
    "source: https://devblogs.nvidia.com/numba-python-cuda-acceleration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([\"int16(int16, int16)\"], target=\"cpu\")\n",
    "def multicpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"int16(int16, int16)\"], target=\"cuda\")\n",
    "def multicuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def expcpu(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def expcuda(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def sincpu(a, b):\n",
    "    return a*math.sin(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def sincuda(a, b):\n",
    "    return a*math.sin(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu3(a, b, c):\n",
    "    return a * b * c\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda3(a, b, c):\n",
    "    return a * b * c\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32, float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu5(a, b, c, d, e):\n",
    "    return a * b * c * d * e\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32, float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda5(a, b, c, d, e):\n",
    "    return a * b * c * d * e\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cpu\")\n",
    "def expsincpu(a, b, c):\n",
    "    return a*math.exp(b)*math.sin(c)\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cuda\")\n",
    "def expsincuda(a, b, c):\n",
    "    return a*math.exp(b)*math.sin(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors_int(s1=100, s2=100):\n",
    "    a = np.random.randint(1, 5, (s1, s2), dtype=np.int16)\n",
    "    b = np.random.randint(1, 10, (s1, s2), dtype=np.int16)\n",
    "    return a, b\n",
    "\n",
    "def factors_float(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    return a, b\n",
    "\n",
    "def factors_float3(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    c = np.random.uniform(low=0, high=10, size=(s1,s2)).astype(np.float32)\n",
    "    return a, b, c\n",
    "\n",
    "def factors_float5(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    c = np.random.uniform(low=0, high=10, size=(s1,s2)).astype(np.float32)\n",
    "    d = np.random.uniform(low=5, high=15, size=(s1,s2)).astype(np.float32)\n",
    "    e = np.random.uniform(low=0, high=30, size=(s1,s2)).astype(np.float32)\n",
    "    return a, b, c, d, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_combinations=[\n",
    "    (100, 100),\n",
    "    (1000, 1000),\n",
    "    (10000, 10000),\n",
    "    (100000, 10000),\n",
    "    (100000, 100000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"n_processors\",\n",
    "           \"cpu_memory\",\n",
    "           \"gpu_name\",\n",
    "           \"gpu_memory\",\n",
    "           \"data_type\",\n",
    "           \"size1\",\n",
    "           \"size2\",\n",
    "           \"operation\",\n",
    "           \"numpy\",\n",
    "           \"numexpr\",\n",
    "           \"numba_cpu\",\n",
    "           \"numba_gpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processors = get_number_processors()\n",
    "cpu_memory = get_ram_memory(units=\"Gb\")\n",
    "gpu_name = get_gpu_name()[0]\n",
    "gpu_memory = get_total_gpu_memory(units=\"Gb\")[0]\n",
    "header = [n_processors, cpu_memory, gpu_name, gpu_memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla-V100-PCIE-16GB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filebase = gpu_name.replace(\" \", \"-\")\n",
    "filebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data\"\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 µs ± 20.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "464 µs ± 18.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.89 µs ± 2.34 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.43 ms ± 4.47 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "213 µs ± 813 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "573 µs ± 8.45 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "214 µs ± 873 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.62 ms ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "89.5 ms ± 591 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "21.4 ms ± 420 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "88 ms ± 845 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "145 ms ± 2.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "900 ms ± 5.09 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "157 ms ± 7.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "927 ms ± 6.64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.43 s ± 51.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.92 s ± 33.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.67 s ± 18.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.86 s ± 21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_int(s1, s2)\n",
    "    operation = \"a*b\"\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multicpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multicuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00143465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.00461905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.089450</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.088043</td>\n",
       "      <td>0.145048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.899621</td>\n",
       "      <td>0.157267</td>\n",
       "      <td>0.927014</td>\n",
       "      <td>1.43426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>8.922588</td>\n",
       "      <td>1.671576</td>\n",
       "      <td>8.855293</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "               data_type   size1   size2 operation     numpy   numexpr  \\\n",
       "0  <class 'numpy.int16'>     100     100       a*b  0.000002  0.000464   \n",
       "1  <class 'numpy.int16'>    1000    1000       a*b  0.000213  0.000573   \n",
       "2  <class 'numpy.int16'>   10000   10000       a*b  0.089450  0.021387   \n",
       "3  <class 'numpy.int16'>  100000   10000       a*b  0.899621  0.157267   \n",
       "4  <class 'numpy.int16'>  100000  100000       a*b  8.922588  1.671576   \n",
       "\n",
       "   numba_cpu   numba_gpu  \n",
       "0   0.000002  0.00143465  \n",
       "1   0.000214  0.00461905  \n",
       "2   0.088043    0.145048  \n",
       "3   0.927014     1.43426  \n",
       "4   8.855293         OOM  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \"_int\" + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Float matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.87 µs ± 3.39 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "470 µs ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.06 µs ± 11.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.43 ms ± 106 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "399 µs ± 730 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "577 µs ± 20.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "423 µs ± 713 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "5.11 ms ± 14.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "177 ms ± 914 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "31.8 ms ± 455 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "176 ms ± 822 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "279 ms ± 36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.74 s ± 6.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "292 ms ± 10.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.73 s ± 5.57 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.81 s ± 38.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17.6 s ± 61.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.7 s ± 61.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17.5 s ± 41.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    operation = \"a*b\"\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0014349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.00511176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.177347</td>\n",
       "      <td>0.031833</td>\n",
       "      <td>0.175587</td>\n",
       "      <td>0.279195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>1.735279</td>\n",
       "      <td>0.291996</td>\n",
       "      <td>1.732133</td>\n",
       "      <td>2.81469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>17.586249</td>\n",
       "      <td>2.701125</td>\n",
       "      <td>17.506866</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "                 data_type   size1   size2 operation      numpy   numexpr  \\\n",
       "0  <class 'numpy.float32'>     100     100       a*b   0.000003  0.000470   \n",
       "1  <class 'numpy.float32'>    1000    1000       a*b   0.000399  0.000577   \n",
       "2  <class 'numpy.float32'>   10000   10000       a*b   0.177347  0.031833   \n",
       "3  <class 'numpy.float32'>  100000   10000       a*b   1.735279  0.291996   \n",
       "4  <class 'numpy.float32'>  100000  100000       a*b  17.586249  2.701125   \n",
       "\n",
       "   numba_cpu   numba_gpu  \n",
       "0   0.000003   0.0014349  \n",
       "1   0.000423  0.00511176  \n",
       "2   0.175587    0.279195  \n",
       "3   1.732133     2.81469  \n",
       "4  17.506866         OOM  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \"_float\" + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.87 µs ± 5.14 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "451 µs ± 34.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.27 µs ± 5.01 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.43 ms ± 5.83 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "398 µs ± 3.68 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "576 µs ± 15.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "422 µs ± 1.04 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "5.05 ms ± 12.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "176 ms ± 678 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "32 ms ± 395 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "175 ms ± 1.75 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "281 ms ± 38.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "1.74 s ± 7.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "290 ms ± 7.63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.73 s ± 13.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.78 s ± 35.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    operation = \"a*exp(b)\"\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2)) \n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sine matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    operation = \"a*sin(b)\"\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))        \n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple matrix multiplication (3 factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c = factors_float3(s1, s2)\n",
    "    operation = \"a*b*c\"\n",
    "    r1 = %timeit -o multiply3(a,b,c)\n",
    "    r2 = %timeit -o ne_multiply3(a,b,c)\n",
    "    r3 = %timeit -o multfcpu3(a,b,c)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda3(a,b,c)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple matrix multiplication (5 factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c, d, e = factors_float5(s1, s2)\n",
    "    operation = \"a*b*c*d*e\"\n",
    "    r1 = %timeit -o multiply5(a,b,c,d,e)\n",
    "    r2 = %timeit -o ne_multiply5(a,b,c,d,e)\n",
    "    r3 = %timeit -o multfcpu5(a,b,c,d,e)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda5(a,b,c,d,e)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential sine matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c = factors_float3(s1, s2)\n",
    "    operation = \"a*exp(b)*sin(c)\"\n",
    "    r1 = %timeit -o exponential_sine(a,b,c)\n",
    "    r2 = %timeit -o ne_exponential_sine(a,b,c)\n",
    "    r3 = %timeit -o expsincpu(a,b,c)\n",
    "    try:\n",
    "        r4 = %timeit -o expsincuda(a,b,c)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))        \n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (benchmark)",
   "language": "python",
   "name": "benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
