{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark of Matrix Multiplications\n",
    "On this benchmark we compare several operations using numpy, numexpr and numba (CPU&GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) \n",
      "[GCC 7.3.0]\n",
      "Numpy version: 1.16.0\n",
      "Pandas version: 0.23.4\n",
      "Numexpr version: 2.6.9\n",
      "PyTorch version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from numba import vectorize\n",
    "from numba.cuda.cudadrv.error import CudaDriverError\n",
    "import math\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils import (get_number_processors, get_ram_memory, get_total_gpu_memory, \n",
    "                   get_gpu_name, get_cuda_version, get_cudnn_version, AttributeDict,\n",
    "                   get_object_size)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Numexpr version: {}\".format(ne.__version__))\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a,b):\n",
    "    return a*b\n",
    "\n",
    "def exponential(a, b):\n",
    "    return a*np.exp(b)\n",
    "\n",
    "def sine(a, b):\n",
    "    return a*np.sin(b)\n",
    "\n",
    "# A general function that multiplies an arbitrary number of matrices\n",
    "# is 28% slower than directly multiplying the factors.\n",
    "# The function multiply_list is not used, just leaving it here for reference\n",
    "def multiply_list(l):\n",
    "    return reduce(lambda x, y: x*y, l) \n",
    "\n",
    "def multiply3(a, b, c):\n",
    "    return a*b*c\n",
    "\n",
    "def multiply5(a, b, c, d, e):\n",
    "    return a*b*c*d*e\n",
    "\n",
    "def exponential_sine(a, b, c):\n",
    "    return a*np.exp(b)*np.sin(c)\n",
    "\n",
    "def dot(a, b):\n",
    "    return np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_multiply(a,b):\n",
    "    return ne.evaluate(\"a*b\")\n",
    "\n",
    "def ne_exponential(a, b):\n",
    "    return ne.evaluate(\"a*exp(b)\")\n",
    "\n",
    "def ne_sine(a, b):\n",
    "    return ne.evaluate(\"a*sin(b)\")\n",
    "\n",
    "def ne_multiply3(a, b, c):\n",
    "    return ne.evaluate(\"a*b*c\")\n",
    "\n",
    "def ne_multiply5(a, b, c, d, e):\n",
    "    return ne.evaluate(\"a*b*c*d*e\")\n",
    "\n",
    "def ne_exponential_sine(a, b, c):\n",
    "    return ne.evaluate(\"a*exp(b)*sin(c)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for numba\n",
    "NOTE: For numba solutions, having a solution empty vector speeds up around 10%\n",
    "```\n",
    "r0 = np.empty((S1, S2), dtype=np.int16)\n",
    "r0 = multicpu(a, b)\n",
    "```\n",
    "source: https://devblogs.nvidia.com/numba-python-cuda-acceleration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([\"int16(int16, int16)\"], target=\"cpu\")\n",
    "def multicpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"int16(int16, int16)\"], target=\"cuda\")\n",
    "def multicuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def expcpu(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def expcuda(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def sincpu(a, b):\n",
    "    return a*math.sin(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def sincuda(a, b):\n",
    "    return a*math.sin(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu3(a, b, c):\n",
    "    return a * b * c\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda3(a, b, c):\n",
    "    return a * b * c\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32, float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu5(a, b, c, d, e):\n",
    "    return a * b * c * d * e\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32, float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda5(a, b, c, d, e):\n",
    "    return a * b * c * d * e\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cpu\")\n",
    "def expsincpu(a, b, c):\n",
    "    return a*math.exp(b)*math.sin(c)\n",
    "\n",
    "@vectorize([\"float32(float32, float32, float32)\"], target=\"cuda\")\n",
    "def expsincuda(a, b, c):\n",
    "    return a*math.exp(b)*math.sin(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for PyTorch\n",
    "\n",
    "*Note on performance*: \n",
    "\n",
    "`torch.as_tensor(a)` does not make a copy of a on CPU. Adding `.cuda()` copies the array to GPU memory.\n",
    "\n",
    "More info: https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_multiply(a,b):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    return at*bt\n",
    "\n",
    "def pt_exponential(a, b):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    return at*torch.exp(bt)\n",
    "\n",
    "def pt_sine(a, b):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    return at*torch.sin(bt)\n",
    "\n",
    "def pt_multiply3(a, b, c):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    ct = torch.as_tensor(c).cuda()\n",
    "    return at*bt*ct\n",
    "\n",
    "def pt_multiply5(a, b, c, d, e):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    ct = torch.as_tensor(c).cuda()\n",
    "    dt = torch.as_tensor(d).cuda()\n",
    "    et = torch.as_tensor(e).cuda()\n",
    "    return at*bt*ct*dt*et\n",
    "\n",
    "def pt_exponential_sine(a, b, c):\n",
    "    at = torch.as_tensor(a).cuda() \n",
    "    bt = torch.as_tensor(b).cuda()\n",
    "    ct = torch.as_tensor(c).cuda()\n",
    "    return at*torch.exp(bt)*torch.sin(ct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_combinations=[\n",
    "    (100, 100),\n",
    "    (1000, 1000),\n",
    "    (10000, 10000),\n",
    "    (100000, 10000),\n",
    "    (100000, 100000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"n_processors\",\n",
    "           \"cpu_memory\",\n",
    "           \"gpu_name\",\n",
    "           \"gpu_memory\",\n",
    "           \"data_type\",\n",
    "           \"size1\",\n",
    "           \"size2\",\n",
    "           \"operation\",\n",
    "           \"numpy\",\n",
    "           \"numexpr\",\n",
    "           \"numba_cpu\",\n",
    "           \"numba_gpu\",\n",
    "           \"pytorch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processors = get_number_processors()\n",
    "cpu_memory = get_ram_memory(units=\"Gb\")\n",
    "gpu_name = get_gpu_name()[0]\n",
    "gpu_memory = get_total_gpu_memory(units=\"Gb\")[0]\n",
    "header = [n_processors, cpu_memory, gpu_name, gpu_memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla-V100-PCIE-16GB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filebase = gpu_name.replace(\" \", \"-\")\n",
    "filebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data\"\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors_int(s1=100, s2=100):\n",
    "    a = np.random.randint(1, 5, (s1, s2), dtype=np.int16)\n",
    "    b = np.random.randint(1, 10, (s1, s2), dtype=np.int16)\n",
    "    return a, b\n",
    "\n",
    "def factors_float(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    return a, b\n",
    "\n",
    "def factors_float3(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    c = np.random.uniform(low=0, high=10, size=(s1,s2)).astype(np.float32)\n",
    "    return a, b, c\n",
    "\n",
    "def factors_float5(s1=100, s2=100):\n",
    "    a = np.random.randn(s1, s2).astype(np.float32)\n",
    "    b = np.random.randn(s1, s2).astype(np.float32)\n",
    "    c = np.random.uniform(low=0, high=10, size=(s1,s2)).astype(np.float32)\n",
    "    d = np.random.uniform(low=5, high=15, size=(s1,s2)).astype(np.float32)\n",
    "    e = np.random.uniform(low=0, high=30, size=(s1,s2)).astype(np.float32)\n",
    "    return a, b, c, d, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data sizes in Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6264515966177\n",
      "37.25290308892727\n"
     ]
    }
   ],
   "source": [
    "a, _ = factors_int(size_combinations[-1][0], size_combinations[-1][1])\n",
    "print(get_object_size(a, units=\"Gb\"))\n",
    "a, _ = factors_float(size_combinations[-1][0], size_combinations[-1][1])\n",
    "print(get_object_size(a, units=\"Gb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "#### Integer matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 µs ± 5.44 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "457 µs ± 15.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.9 µs ± 4.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.47 ms ± 87.5 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "85.5 µs ± 28.6 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "213 µs ± 852 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "593 µs ± 13.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "208 µs ± 192 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.3 ms ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "577 µs ± 3.35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "88.6 ms ± 539 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "21.6 ms ± 565 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "88.2 ms ± 184 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "137 ms ± 2.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "46.9 ms ± 69.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "901 ms ± 4.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "183 ms ± 3.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "888 ms ± 4.62 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.32 s ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "474 ms ± 1.86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "8.93 s ± 18.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.75 s ± 18.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.78 s ± 17.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n",
      "OOM for size (100000,100000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*b\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_int(s1, s2)\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multicpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multicuda(a,b)\n",
    "    except CudaDriverError: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "      <th>pytorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00146729</td>\n",
       "      <td>8.5454e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.00430323</td>\n",
       "      <td>0.000577085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0.088240</td>\n",
       "      <td>0.136882</td>\n",
       "      <td>0.046876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.900896</td>\n",
       "      <td>0.183345</td>\n",
       "      <td>0.887828</td>\n",
       "      <td>1.32111</td>\n",
       "      <td>0.473809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>8.931365</td>\n",
       "      <td>1.754425</td>\n",
       "      <td>8.775940</td>\n",
       "      <td>OOM</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "               data_type   size1   size2 operation     numpy   numexpr  \\\n",
       "0  <class 'numpy.int16'>     100     100       a*b  0.000002  0.000457   \n",
       "1  <class 'numpy.int16'>    1000    1000       a*b  0.000213  0.000593   \n",
       "2  <class 'numpy.int16'>   10000   10000       a*b  0.088591  0.021648   \n",
       "3  <class 'numpy.int16'>  100000   10000       a*b  0.900896  0.183345   \n",
       "4  <class 'numpy.int16'>  100000  100000       a*b  8.931365  1.754425   \n",
       "\n",
       "   numba_cpu   numba_gpu      pytorch  \n",
       "0   0.000002  0.00146729   8.5454e-05  \n",
       "1   0.000208  0.00430323  0.000577085  \n",
       "2   0.088240    0.136882     0.046876  \n",
       "3   0.887828     1.32111     0.473809  \n",
       "4   8.775940         OOM          OOM  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \"_int\" + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Float matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.05 µs ± 13.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "458 µs ± 11.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.1 µs ± 10.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.48 ms ± 5.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "80.1 µs ± 810 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "397 µs ± 4.98 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "565 µs ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "429 µs ± 3.35 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.79 ms ± 37 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "944 µs ± 11.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "176 ms ± 899 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "31.5 ms ± 257 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "177 ms ± 2.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "265 ms ± 37.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "94.7 ms ± 766 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "1.74 s ± 10.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "287 ms ± 9.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.75 s ± 8.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.67 s ± 16.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "954 ms ± 5.14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "17.4 s ± 83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.74 s ± 87.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17.4 s ± 35.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n",
      "OOM for size (100000,100000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*b\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "      <th>pytorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.00147518</td>\n",
       "      <td>8.0105e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.00479381</td>\n",
       "      <td>0.000943827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>0.175588</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>0.177034</td>\n",
       "      <td>0.264888</td>\n",
       "      <td>0.0946686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>1.742532</td>\n",
       "      <td>0.287435</td>\n",
       "      <td>1.748335</td>\n",
       "      <td>2.67361</td>\n",
       "      <td>0.954018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*b</td>\n",
       "      <td>17.414992</td>\n",
       "      <td>2.741685</td>\n",
       "      <td>17.431799</td>\n",
       "      <td>OOM</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "                 data_type   size1   size2 operation      numpy   numexpr  \\\n",
       "0  <class 'numpy.float32'>     100     100       a*b   0.000003  0.000458   \n",
       "1  <class 'numpy.float32'>    1000    1000       a*b   0.000397  0.000565   \n",
       "2  <class 'numpy.float32'>   10000   10000       a*b   0.175588  0.031534   \n",
       "3  <class 'numpy.float32'>  100000   10000       a*b   1.742532  0.287435   \n",
       "4  <class 'numpy.float32'>  100000  100000       a*b  17.414992  2.741685   \n",
       "\n",
       "   numba_cpu   numba_gpu      pytorch  \n",
       "0   0.000003  0.00147518   8.0105e-05  \n",
       "1   0.000429  0.00479381  0.000943827  \n",
       "2   0.177034    0.264888    0.0946686  \n",
       "3   1.748335     2.67361     0.954018  \n",
       "4  17.431799         OOM          OOM  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \"_float\" + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98 µs ± 7.78 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "432 µs ± 40.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.08 µs ± 7.77 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.44 ms ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "77.7 µs ± 739 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "397 µs ± 4.51 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "589 µs ± 28.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "428 µs ± 6.84 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.86 ms ± 136 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "938 µs ± 12.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "175 ms ± 1.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "31.8 ms ± 496 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "174 ms ± 317 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "264 ms ± 36.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "95.4 ms ± 739 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "1.74 s ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "285 ms ± 11.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.75 s ± 13.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.69 s ± 6.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "957 ms ± 4.07 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "17.5 s ± 37.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.83 s ± 116 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17.4 s ± 17.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n",
      "OOM for size (100000,100000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*exp(b)\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2)) \n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "      <th>pytorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*exp(b)</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.00144215</td>\n",
       "      <td>7.76956e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*exp(b)</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.00485586</td>\n",
       "      <td>0.000938266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*exp(b)</td>\n",
       "      <td>0.175120</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.174266</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>0.0953557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*exp(b)</td>\n",
       "      <td>1.738481</td>\n",
       "      <td>0.284795</td>\n",
       "      <td>1.747448</td>\n",
       "      <td>2.68874</td>\n",
       "      <td>0.957177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*exp(b)</td>\n",
       "      <td>17.508171</td>\n",
       "      <td>2.832436</td>\n",
       "      <td>17.421199</td>\n",
       "      <td>OOM</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "                 data_type   size1   size2 operation      numpy   numexpr  \\\n",
       "0  <class 'numpy.float32'>     100     100  a*exp(b)   0.000003  0.000432   \n",
       "1  <class 'numpy.float32'>    1000    1000  a*exp(b)   0.000397  0.000589   \n",
       "2  <class 'numpy.float32'>   10000   10000  a*exp(b)   0.175120  0.031774   \n",
       "3  <class 'numpy.float32'>  100000   10000  a*exp(b)   1.738481  0.284795   \n",
       "4  <class 'numpy.float32'>  100000  100000  a*exp(b)  17.508171  2.832436   \n",
       "\n",
       "   numba_cpu   numba_gpu      pytorch  \n",
       "0   0.000003  0.00144215  7.76956e-05  \n",
       "1   0.000428  0.00485586  0.000938266  \n",
       "2   0.174266    0.263535    0.0953557  \n",
       "3   1.747448     2.68874     0.957177  \n",
       "4  17.421199         OOM          OOM  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sine matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.04 µs ± 51.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "469 µs ± 16.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "3.09 µs ± 17.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.45 ms ± 3.87 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "78.3 µs ± 375 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "401 µs ± 1.34 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "556 µs ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "428 µs ± 600 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.79 ms ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "947 µs ± 12.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "175 ms ± 1.53 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "31.6 ms ± 165 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "173 ms ± 855 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "258 ms ± 37.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "94.2 ms ± 763 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "1.73 s ± 9.07 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "286 ms ± 10.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.76 s ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.66 s ± 27.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "956 ms ± 5.06 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "17.4 s ± 49.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.77 s ± 74.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17.4 s ± 61.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,100000)\n",
      "OOM for size (100000,100000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*sin(b)\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b = factors_float(s1, s2)\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multfcpu(a,b)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda(a,b)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))        \n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "      <th>pytorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a*sin(b)</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.00144839</td>\n",
       "      <td>7.83187e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a*sin(b)</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.00478838</td>\n",
       "      <td>0.00094656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*sin(b)</td>\n",
       "      <td>0.175495</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>0.172847</td>\n",
       "      <td>0.258442</td>\n",
       "      <td>0.0941856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>a*sin(b)</td>\n",
       "      <td>1.725402</td>\n",
       "      <td>0.285651</td>\n",
       "      <td>1.756081</td>\n",
       "      <td>2.66361</td>\n",
       "      <td>0.956336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909752</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.float32'&gt;</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>a*sin(b)</td>\n",
       "      <td>17.438768</td>\n",
       "      <td>2.767125</td>\n",
       "      <td>17.360333</td>\n",
       "      <td>OOM</td>\n",
       "      <td>OOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors  cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "4           24  440.909752  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "                 data_type   size1   size2 operation      numpy   numexpr  \\\n",
       "0  <class 'numpy.float32'>     100     100  a*sin(b)   0.000003  0.000469   \n",
       "1  <class 'numpy.float32'>    1000    1000  a*sin(b)   0.000401  0.000556   \n",
       "2  <class 'numpy.float32'>   10000   10000  a*sin(b)   0.175495  0.031560   \n",
       "3  <class 'numpy.float32'>  100000   10000  a*sin(b)   1.725402  0.285651   \n",
       "4  <class 'numpy.float32'>  100000  100000  a*sin(b)  17.438768  2.767125   \n",
       "\n",
       "   numba_cpu   numba_gpu      pytorch  \n",
       "0   0.000003  0.00144839  7.83187e-05  \n",
       "1   0.000428  0.00478838   0.00094656  \n",
       "2   0.172847    0.258442    0.0941856  \n",
       "3   1.756081     2.66361     0.956336  \n",
       "4  17.360333         OOM          OOM  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple matrix multiplication (3 factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46 µs ± 27.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "449 µs ± 11.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "5.68 µs ± 42 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.88 ms ± 78.9 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "77.7 µs ± 648 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "713 µs ± 1.96 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "626 µs ± 31.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "530 µs ± 5.15 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "6.38 ms ± 97.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "946 µs ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "257 ms ± 3.84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "43.8 ms ± 703 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "208 ms ± 2.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "323 ms ± 39.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "94.7 ms ± 481 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "2.53 s ± 12.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "407 ms ± 16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.07 s ± 15.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "OOM for size (100000,10000)\n",
      "942 ms ± 1.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*b*c\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c = factors_float3(s1, s2)\n",
    "    r1 = %timeit -o multiply3(a,b,c)\n",
    "    r2 = %timeit -o ne_multiply3(a,b,c)\n",
    "    r3 = %timeit -o multfcpu3(a,b,c)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda3(a,b,c)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple matrix multiplication (5 factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*b*c*d*e\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c, d, e = factors_float5(s1, s2)\n",
    "    r1 = %timeit -o multiply5(a,b,c,d,e)\n",
    "    r2 = %timeit -o ne_multiply5(a,b,c,d,e)\n",
    "    r3 = %timeit -o multfcpu5(a,b,c,d,e)\n",
    "    try:\n",
    "        r4 = %timeit -o multfcuda5(a,b,c,d,e)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential sine matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "operation = \"a*exp(b)*sin(c)\"\n",
    "for s1, s2 in size_combinations:\n",
    "    a, b, c = factors_float3(s1, s2)\n",
    "    r1 = %timeit -o exponential_sine(a,b,c)\n",
    "    r2 = %timeit -o ne_exponential_sine(a,b,c)\n",
    "    r3 = %timeit -o expsincpu(a,b,c)\n",
    "    try:\n",
    "        r4 = %timeit -o expsincuda(a,b,c)\n",
    "    except: # in case of Out Of Memory (OOM)\n",
    "        r4 = AttributeDict()\n",
    "        r4[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))        \n",
    "    try:\n",
    "        r5 = %timeit -o pt_multiply(a,b)\n",
    "    except RuntimeError: # in case of Out Of Memory (OOM)\n",
    "        r5 = AttributeDict()\n",
    "        r5[\"average\"] = \"OOM\"\n",
    "        print(\"OOM for size ({},{})\".format(s1, s2))\n",
    "    print(\"\")\n",
    "    row = header + [type(a[0,0]), s1, s2, operation, r1.average, r2.average, r3.average, r4.average, r5.average]\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = filebase + \"_\" + operation + \".csv\"\n",
    "df.to_csv(os.path.join(folder, filename), index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (benchmark)",
   "language": "python",
   "name": "benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
