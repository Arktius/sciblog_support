{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 19:16:44) \n",
      "[GCC 7.3.0]\n",
      "Numpy version: 1.15.4\n",
      "Pandas version: 0.23.4\n",
      "Numexpr version: 2.6.9\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from numba import vectorize\n",
    "import math\n",
    "import pandas as pd\n",
    "import bokeh\n",
    "from utils import (get_number_processors, get_ram_memory, get_total_gpu_memory, \n",
    "                   get_gpu_name, get_cuda_version, get_cudnn_version)\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Numpy version: {}\".format(np.__version__))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Numexpr version: {}\".format(ne.__version__))\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a,b):\n",
    "    return a*b\n",
    "\n",
    "def exponential(a, b):\n",
    "    return a * np.exp(b)\n",
    "\n",
    "def sine(a, b):\n",
    "    return a * np.sin(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function with numpexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_multiply(a,b):\n",
    "    return ne.evaluate(\"a*b\")\n",
    "\n",
    "def ne_exponential(a, b):\n",
    "    return ne.evaluate(\"a*exp(b)\")\n",
    "\n",
    "def ne_sine(a, b):\n",
    "    return ne.evaluate(\"a*sin(b)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for numba\n",
    "NOTE: For numba solutions, having a solution empty vector speeds up around 10%\n",
    "```\n",
    "r0 = np.empty((S1, S2), dtype=np.int16)\n",
    "r0 = multicpu(a, b)\n",
    "```\n",
    "source: https://devblogs.nvidia.com/numba-python-cuda-acceleration/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([\"int16(int16, int16)\"], target=\"cpu\")\n",
    "def multicpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"int16(int16, int16)\"], target=\"cuda\")\n",
    "def multicuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def multfcpu(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def multfcuda(a, b):\n",
    "    return a * b\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def expcpu(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def expcuda(a, b):\n",
    "    return a*math.exp(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cpu\")\n",
    "def sincpu(a, b):\n",
    "    return a*math.sin(b)\n",
    "\n",
    "@vectorize([\"float32(float32, float32)\"], target=\"cuda\")\n",
    "def sincuda(a, b):\n",
    "    return a*math.sin(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors_int(S1=100, S2=100):\n",
    "    a = np.random.randint(1, 5, (S1, S2), dtype=np.int16)\n",
    "    b = np.random.randint(1, 10, (S1, S2), dtype=np.int16)\n",
    "    return a, b\n",
    "\n",
    "def factor_float(S1=100, S2=100):\n",
    "    a = np.random.randn(S1, S2).astype(np.float32)\n",
    "    b = np.random.randn(S1, S2).astype(np.float32)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_combinations=[\n",
    "    (100, 100),\n",
    "    (1000, 1000),\n",
    "    (10000, 10000),\n",
    "    (100000, 10000),\n",
    "#    (100000, 100000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"n_processors\",\n",
    "           \"cpu_memory\",\n",
    "           \"gpu_name\",\n",
    "           \"gpu_memory\",\n",
    "           \"data_type\",\n",
    "           \"size1\",\n",
    "           \"size2\",\n",
    "           \"operation\",\n",
    "           \"numpy\",\n",
    "           \"numexpr\",\n",
    "           \"numba_cpu\",\n",
    "           \"numba_gpu\"]\n",
    "df = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processors = get_number_processors()\n",
    "cpu_memory = get_ram_memory(units=\"Gb\")\n",
    "gpu_name = get_gpu_name()[0]\n",
    "gpu_memory = get_total_gpu_memory(units=\"Gb\")[0]\n",
    "header = [n_processors, cpu_memory, gpu_name, gpu_memory]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 µs ± 3.42 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "464 µs ± 27.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "2.04 µs ± 16.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.33 ms ± 2.29 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "213 µs ± 654 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "583 µs ± 21.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "211 µs ± 581 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.35 ms ± 28.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "for S1, S2 in size_combinations:\n",
    "    a, b = factors_int(S1, S2)\n",
    "    operation = \"a * b\"\n",
    "    r1 = %timeit -o multiply(a,b)\n",
    "    r2 = %timeit -o ne_multiply(a,b)\n",
    "    r3 = %timeit -o multicpu(a,b)\n",
    "    r4 = %timeit -o multicuda(a,b)\n",
    "    row = header + [type(a[0,0]), S1, S2, operation, r1.average, r2.average, r3.average, r4.average]\n",
    "    df.loc[len(df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processors</th>\n",
       "      <th>cpu_memory</th>\n",
       "      <th>gpu_name</th>\n",
       "      <th>gpu_memory</th>\n",
       "      <th>data_type</th>\n",
       "      <th>size1</th>\n",
       "      <th>size2</th>\n",
       "      <th>operation</th>\n",
       "      <th>numpy</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba_cpu</th>\n",
       "      <th>numba_gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>451491.589844</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a * b</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>451491.589844</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a * b</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>a * b</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>440.909756</td>\n",
       "      <td>Tesla V100-PCIE-16GB</td>\n",
       "      <td>15.781738</td>\n",
       "      <td>&lt;class 'numpy.int16'&gt;</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>a * b</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_processors     cpu_memory              gpu_name  gpu_memory  \\\n",
       "0           24  451491.589844  Tesla V100-PCIE-16GB   15.781738   \n",
       "1           24  451491.589844  Tesla V100-PCIE-16GB   15.781738   \n",
       "2           24     440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "3           24     440.909756  Tesla V100-PCIE-16GB   15.781738   \n",
       "\n",
       "               data_type size1 size2 operation     numpy   numexpr  numba_cpu  \\\n",
       "0  <class 'numpy.int16'>   100   100     a * b  0.000002  0.000397   0.000002   \n",
       "1  <class 'numpy.int16'>  1000  1000     a * b  0.000212  0.000591   0.000211   \n",
       "2  <class 'numpy.int16'>   100   100     a * b  0.000002  0.000464   0.000002   \n",
       "3  <class 'numpy.int16'>  1000  1000     a * b  0.000213  0.000583   0.000211   \n",
       "\n",
       "   numba_gpu  \n",
       "0   0.001322  \n",
       "1   0.004364  \n",
       "2   0.001330  \n",
       "3   0.004353  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (benchmark)",
   "language": "python",
   "name": "benchmark"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
